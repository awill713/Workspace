%% script: Kath Rick's new correlation code...

clear

mice = {'K070','K073','K074'};

for mm = 1:length(mice)
    
    xl = xlsread('D:\2Pdata\mouseCellTracking.xlsx',mice{mm});
    
    fileIndex = find(~isnan(xl(:,1)));
    fileDates = xl(fileIndex,3);
    fileFolders = xl(fileIndex,5);
    
    for ii = 1:length(fileIndex)
        filename = dir(['D:\2Pdata\data\' mice{mm} sprintf('_%d_2P_FRA_%02d*',fileDates(ii),fileFolders(ii))]);
        load([filename.folder filesep filename.name])
        % Get the correlation matrices
        % RICK: The basic idea is that you'll compute a correlation matrix that you'll
        % then compare to an ensemble of correlation matrices generated by randomly
        % and independently offsetting (jittering) each neuron's time series some
        % number of samples (the upper and lower bounds are determined by the
        % sampling frequency and offset parameter). I used a 1 second offset in my
        % simulations, which meant that in my null models neurons' time series
        % could be shifted +/-30 samples with respect to one another.
        %
        % The fifth output of the function is a z-score map -- number of stdv
        % above/below the magnitude of observed correlations were compared to the
        % jittered correlations.
        %
        % I applied some thresholds to the z-score map (e.g. 2 standard deviations)
        % and set all correlations above that threshold to have a weight of 1 and
        % everything below to be 0. Then I did all my network analysis on the
        % binary networks.
        
        [dff,~,~,gt,z] = fcn_jit(calcium.npilSubTraces,exptInfo.fr,1,500); 
        % sampling frequency (in Hz), an offset parameter (in seconds),
        % and the number of randomizations you want to run.
        
        bnet = zeros(size(z)); % binary network
        bnet(z > 2) = 1; 
        
        %% estimate modules
        %% modularity maximization
        % we've tried a few different clustering approaches. a really popular
        % method is "modularity maximization" (newman & girvan 2004).
        %
        % modularity maximization tries to optimize a particular objective function
        % called "modularity" or "Q". the goal is to divide a network into clusters
        % whose internal density of connections (mean connection strength among all
        % nodes assigned to the same cluster) is maximally greater than a
        % chance/null model.
        %
        % this method has one free parameter, gamma, that determines the
        % number/size of clusters. when gamma is small, you get few clusters, but
        % when its large you get many smal clusters.
        %
        % the user also has to specify the chance/random connectivity profile. we
        % follow a recent paper and use a "flat" model (bazzi et al 2016,
        % multiscale model.). there are others but this one works well when the
        % network is estimated from a correlation matrix.
        %
        % the software package we use to implement modularity maximization is the a
        % so-called generalized louvain algorithm. you can download it here:
        %   http://netwiki.amath.unc.edu/GenLouvain/GenLouvain
        %
        % let me know if you have trouble installing -- i think the newest version
        % doesn't require any compiling. just add the directories to your current
        % path.
        %
        %
        % the function "fcn_genlouvain.m" will implement this step.
        addpath(genpath('GenLouvain-master\'))
        N = length(bnet);      % number of nodes
        ngam = 41;          % number of gamma values to test
        nreps = 100;        % number of restarts of the louvain algorithm
        mask = triu(ones(N),1) > 0;     % upper triangle mask
        mu = mean(bnet(mask));             % mean connection weight
        sd = std(bnet(mask));              % stdv connection weight
%         gammavals = ...                 % gamma values to test
%             linspace(0,1,ngam)*sd + mu;
        gammavals = [0.400000000000000,0.458953660632285,0.521400545269871,...
            0.587547640447950,0.657614197424988,0.731832458913261,0.810448428870897,...
            0.893722687906948,0.981931257002264,1.07536651240904,1.17433815476155,...
            1.27917423561037,1.39022224478246,1.50785026217152,1.63244817777611,...
            1.76442898402959,1.90423014470549,2.05231504493555,2.20917452714674,...
            2.37532851800833,2.55132775178155,2.73775559578417,2.93522998402072,...
            3.14440546538739,3.36597537324079,3.60067412352169,3.84927964905119,...
            4.11261597806797,4.39155596555351,4.68702418639847,5];
         ngam = length(gammavals);          % number of gamma values to test
%         name = 'exampleCommunitiesQmax.mat';
%         check = dir(name);
%         if isempty(check)
            ci = zeros(N,nreps,ngam);
            for igam = 1:ngam
                B = (bnet - gammavals(igam)).*~eye(N); % make a "modularity matrix"
                for irep = 1:nreps
                    ci(:,irep,igam) = genlouvain(B);% feed matrix to algorithm
                end
            end
%             save(name,'ci','gammavals');
%         else
%             load(name);
%         end
        %% choose optimal gamma
        % again, lots of strategies for choosing gamma (i.e. number/size of
        % clusters). one heuristic is to focus on gamma values for which the
        % algorithm repeatedly converges to the same (or similar) cluster
        % solutions.
        %
        % here, we use the z-score of the rand index to measure similarity.
        % basically, it tells us how much more similar to cluster partitions are to
        % one another compared to a null distribution (traud et al 2011).
        %
        % we'll focus on local maxima of the median z-score rand index versus gamma
        % curve. to identiy ``stable'' maxima, we'll take random sub-samples of the
        % all pairwise similarity scores and identify local maxima that are present
        % consistently across subsamples.
        %
        %
        % the function "fcn_choose_gamma.m" will implement this step.
        
        subsample = round(nreps/2);             % number of partitions in subsample
        nsubsample = 100;                       % number of subsamples
        mask = triu(ones(nreps),1) > 0;         % upper triangle mask
        masksub = triu(ones(subsample),1) > 0;  % a different upper triangle mask
        med = zeros(1,ngam);                    % vector to store median similarity over ALL cluster partitions
        medsubsample = zeros(nsubsample,ngam);  % matrix to store median similarity from subsamples
        for igam = 1:ngam                       % loop over gamma
            z = zeros(nreps);                   % we'll temporarily store similarity scores here.
            for irep = 1:(nreps - 1)            % loop over pairs of partitions
                for jrep = (irep + 1):nreps
                    z(irep,jrep) = fcn_zrand(ci(:,irep,igam),ci(:,jrep,igam));  % compute similarity
                    z(jrep,irep) = z(irep,jrep);                                % z-score rand index is symmetric, so z(i,j) is the same as z(j,i)
                end
            end
            med(igam) = median(z(mask));        % get median similarity
            for isub = 1:nsubsample             % randomly subsample
                r = randperm(nreps,subsample);  % select pairs at random
                zsub = z(r,r);                  % extract subsampled matrix
                medsubsample(isub,igam) = median(zsub(masksub));    % compute median z-score rand index
            end
            ph = plot(1:igam,medsubsample(:,1:igam),1:igam,med(1:igam));    % make a plot
            set(ph(end),'color','k','linewidth',2);
            drawnow;
        end
        %%
        
        pks = zeros(size(medsubsample));
        for isub = 1:nsubsample                 % loop over subsamples and find peaks
            idx = findpeaks(medsubsample(isub,:));
            pks(isub,idx.loc) = 1;
        end
        % mu = mean(pks,1) >= 0.95;               % keep peaks that are consistent in 95% of subsamples
        threshold = 0.95;
        mu = mean(pks,1) >= threshold;               % keep peaks that are consistent in 95% of subsamples
        while sum(mu)==0
            threshold = threshold-0.01;
            disp(threshold)
            mu = mean(pks,1) >= threshold;
        end
        t = threshold;
        while sum(mu)==1
            threshold = threshold-0.01;
            disp(threshold)
            mu = mean(pks,1) >= threshold;
        end
        t(2) = threshold;
        cipks = ci(:,:,mu==1);
        cicon = zeros(N,size(cipks,3));         % do consensus clustering to get "representative" clusters (lancichinetti & fortunato 2012, sci. rep.)
%         for j = 1:size(cipks,3)
%             cicon(:,j) = fcn_consensus_communities(cipks(:,:,j),nreps,true); %  these represent the final clusters -- you'll get multiple resolutions (different number/size of clusters) that will be more/less-suited for behavioral analysis
%         end
          for j = 1:size(ci,3)
            cicon(:,j) = fcn_consensus_communities(ci(:,:,j),nreps,true); %  these represent the final clusters -- you'll get multiple resolutions (different number/size of clusters) that will be more/less-suited for behavioral analysis
          end
        
        
        %% save
        network.bnet = bnet;
        network.ci = ci;
        network.gamma = gammavals;
        if size(cicon,2)>length(t)
            t(length(t)+1:size(cicon,2)) = t(end);
        end
        network.thresholds = t;
        network.conCom = cicon;
        s = zeros(1,size(cicon,2));
        for comi = 1:size(cicon,2)
            s(comi) = length(unique(cicon(:,comi)));
        end
        network.comSizes = s;
        
        save([filename.folder filesep filename.name],'network','-append');
        
        days{ii} = fileDates(ii);
        coor{ii} = spatialInfo.centroid;
        cells{ii} = spatialInfo.masterCellIndex;
        gammavalues{ii} = gammavals;
        communities{ii} = cicon;
        
    end
end
